# Projects Done

This page is to showcase all the projects done. It includes Data Science and Data Engineering projects. 

## Data Science Projects


<center><img src="images/fraud_detection.jpg"/></center>

### Logistic Regression: Lead Classification

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/artik-gupta/Lead-Score-Case-study-assignment.git)
> This is a project done in the Data Science Post graduation course of IIIT Banglore.

In this project, a Logistic Regression model was trained and tested to classify whether a lead is a potential customer or not. 
Steps include:
1. A data set was taken and preprocessing has been done to clean and further improve the data. Various redundant columns have been removed and null values have been filled as per business understanding.
2. EDA including univariate and bivariate analysis.
3. Feature engineering.
4. RFE technique is used to eliminate the redundant feature having little importance.
5. Statsmodel library is used to train the model.
6. Finally I got around 83% accuracy in the test set and 78% on the train set.


### Exploratory Data Analysis

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/artik-gupta/EDA.git)
> This is a project done in the Data Science Post graduation course of IIIT Banglore.

In this project, an Exploratory data analysis has been done including univariate and bivariate analysis.


### Linear Regression: Customer prediction

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/artik-gupta/Linear-Regression-Project.git)
> This is a project done in the Data Science Post graduation course of IIIT Banglore.

In this project, a Linear Regression model was trained and tested to predict the number of customers by considering weather, season, holidays, and festivals.
Steps include:
1. The Statsmodel library is used to train the model. Various sets of features were being tried to reach an optimal feature set.
2. Residual distribution followed a normal distribution and R2 value of 78% was achieved.
